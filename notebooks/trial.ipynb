{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloc = \"data\"\n",
    "carhacking = \"Car_Hacking_Challenge_Dataset_rev20Mar2021\"\n",
    "prelim = \"0_Preliminary\"\n",
    "training = \"0_Training\"\n",
    "filename_1 = \"Pre_train_D_1.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "prelim_train_dir = os.path.join(\"..\", dataloc, \"raw\", carhacking, prelim, training)\n",
    "csv1 = os.path.join(prelim_train_dir, filename_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Arbitration_ID</th>\n",
       "      <th>DLC</th>\n",
       "      <th>Data</th>\n",
       "      <th>Class</th>\n",
       "      <th>SubClass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.597760e+09</td>\n",
       "      <td>153</td>\n",
       "      <td>8</td>\n",
       "      <td>20 A1 10 FF 00 FF 50 1F</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.597760e+09</td>\n",
       "      <td>220</td>\n",
       "      <td>8</td>\n",
       "      <td>13 24 7F 60 05 FF BF 10</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.597760e+09</td>\n",
       "      <td>507</td>\n",
       "      <td>4</td>\n",
       "      <td>08 00 00 01</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.597760e+09</td>\n",
       "      <td>356</td>\n",
       "      <td>8</td>\n",
       "      <td>00 00 00 80 16 00 00 00</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.597760e+09</td>\n",
       "      <td>340</td>\n",
       "      <td>8</td>\n",
       "      <td>FC 03 00 E4 B7 21 FA 3C</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Timestamp Arbitration_ID  DLC                     Data   Class SubClass\n",
       "0  1.597760e+09            153    8  20 A1 10 FF 00 FF 50 1F  Normal   Normal\n",
       "1  1.597760e+09            220    8  13 24 7F 60 05 FF BF 10  Normal   Normal\n",
       "2  1.597760e+09            507    4              08 00 00 01  Normal   Normal\n",
       "3  1.597760e+09            356    8  00 00 00 80 16 00 00 00  Normal   Normal\n",
       "4  1.597760e+09            340    8  FC 03 00 E4 B7 21 FA 3C  Normal   Normal"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(csv1, encoding='unicode_escape')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Arbitration_ID</th>\n",
       "      <th>DLC</th>\n",
       "      <th>Data</th>\n",
       "      <th>Class</th>\n",
       "      <th>SubClass</th>\n",
       "      <th>d1</th>\n",
       "      <th>d2</th>\n",
       "      <th>d3</th>\n",
       "      <th>d4</th>\n",
       "      <th>d5</th>\n",
       "      <th>d6</th>\n",
       "      <th>d7</th>\n",
       "      <th>d8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.597760e+09</td>\n",
       "      <td>153</td>\n",
       "      <td>8</td>\n",
       "      <td>20 A1 10 FF 00 FF 50 1F</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "      <td>20</td>\n",
       "      <td>A1</td>\n",
       "      <td>10</td>\n",
       "      <td>FF</td>\n",
       "      <td>00</td>\n",
       "      <td>FF</td>\n",
       "      <td>50</td>\n",
       "      <td>1F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.597760e+09</td>\n",
       "      <td>220</td>\n",
       "      <td>8</td>\n",
       "      <td>13 24 7F 60 05 FF BF 10</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "      <td>13</td>\n",
       "      <td>24</td>\n",
       "      <td>7F</td>\n",
       "      <td>60</td>\n",
       "      <td>05</td>\n",
       "      <td>FF</td>\n",
       "      <td>BF</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.597760e+09</td>\n",
       "      <td>507</td>\n",
       "      <td>4</td>\n",
       "      <td>08 00 00 01</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "      <td>08</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.597760e+09</td>\n",
       "      <td>356</td>\n",
       "      <td>8</td>\n",
       "      <td>00 00 00 80 16 00 00 00</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>80</td>\n",
       "      <td>16</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.597760e+09</td>\n",
       "      <td>340</td>\n",
       "      <td>8</td>\n",
       "      <td>FC 03 00 E4 B7 21 FA 3C</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "      <td>FC</td>\n",
       "      <td>03</td>\n",
       "      <td>00</td>\n",
       "      <td>E4</td>\n",
       "      <td>B7</td>\n",
       "      <td>21</td>\n",
       "      <td>FA</td>\n",
       "      <td>3C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Timestamp Arbitration_ID  DLC                     Data   Class SubClass  \\\n",
       "0  1.597760e+09            153    8  20 A1 10 FF 00 FF 50 1F  Normal   Normal   \n",
       "1  1.597760e+09            220    8  13 24 7F 60 05 FF BF 10  Normal   Normal   \n",
       "2  1.597760e+09            507    4              08 00 00 01  Normal   Normal   \n",
       "3  1.597760e+09            356    8  00 00 00 80 16 00 00 00  Normal   Normal   \n",
       "4  1.597760e+09            340    8  FC 03 00 E4 B7 21 FA 3C  Normal   Normal   \n",
       "\n",
       "   d1  d2  d3  d4    d5    d6    d7    d8  \n",
       "0  20  A1  10  FF    00    FF    50    1F  \n",
       "1  13  24  7F  60    05    FF    BF    10  \n",
       "2  08  00  00  01  None  None  None  None  \n",
       "3  00  00  00  80    16    00    00    00  \n",
       "4  FC  03  00  E4    B7    21    FA    3C  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"d1\", \"d2\", \"d3\", \"d4\", \"d5\", \"d6\", \"d7\", \"d8\"]] = df.Data.str.split(\" \", expand=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1234"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"d3\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"d1_int\"] = df.apply(lambda x: 999 if x[\"d1\"] is None else int(x[\"d1\"], 16), axis=1)\n",
    "df[\"d2_int\"] = df.apply(lambda x: 999 if x[\"d2\"] is None else int(x[\"d2\"], 16), axis=1)\n",
    "df[\"d3_int\"] = df.apply(lambda x: 999 if x[\"d3\"] is None else int(x[\"d3\"], 16), axis=1)\n",
    "df[\"d4_int\"] = df.apply(lambda x: 999 if x[\"d4\"] is None else int(x[\"d4\"], 16), axis=1)\n",
    "\n",
    "df[\"d5_int\"] = df.apply(lambda x: 999 if x[\"d5\"] is None else int(x[\"d5\"], 16), axis=1)\n",
    "df[\"d6_int\"] = df.apply(lambda x: 999 if x[\"d6\"] is None else int(x[\"d6\"], 16), axis=1)\n",
    "df[\"d7_int\"] = df.apply(lambda x: 999 if x[\"d7\"] is None else int(x[\"d7\"], 16), axis=1)\n",
    "df[\"d8_int\"] = df.apply(lambda x: 999 if x[\"d8\"] is None else int(x[\"d8\"], 16), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 806390 entries, 0 to 806389\n",
      "Data columns (total 22 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   Timestamp       806390 non-null  float64\n",
      " 1   Arbitration_ID  806390 non-null  object \n",
      " 2   DLC             806390 non-null  int64  \n",
      " 3   Data            806390 non-null  object \n",
      " 4   Class           806390 non-null  object \n",
      " 5   SubClass        806390 non-null  object \n",
      " 6   d1              806390 non-null  object \n",
      " 7   d2              806390 non-null  object \n",
      " 8   d3              805156 non-null  object \n",
      " 9   d4              805156 non-null  object \n",
      " 10  d5              743095 non-null  object \n",
      " 11  d6              727685 non-null  object \n",
      " 12  d7              695249 non-null  object \n",
      " 13  d8              663856 non-null  object \n",
      " 14  d1_int          806390 non-null  int64  \n",
      " 15  d2_int          806390 non-null  int64  \n",
      " 16  d3_int          806390 non-null  int64  \n",
      " 17  d4_int          806390 non-null  int64  \n",
      " 18  d5_int          806390 non-null  int64  \n",
      " 19  d6_int          806390 non-null  int64  \n",
      " 20  d7_int          806390 non-null  int64  \n",
      " 21  d8_int          806390 non-null  int64  \n",
      "dtypes: float64(1), int64(9), object(12)\n",
      "memory usage: 135.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 32, 161,  16, ..., 255,  80,  31],\n",
       "       [ 19,  36, 127, ..., 255, 191,  16],\n",
       "       [  8,   0,   0, ..., 999, 999, 999],\n",
       "       ...,\n",
       "       [  0,   0,   0, ...,  40,  11,  66],\n",
       "       [  4, 127, 255, ..., 123,   0,  38],\n",
       "       [  0,   0,   0, ...,   0,   0,   0]], dtype=int64)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[[\"d1_int\", \"d2_int\", \"d3_int\", \"d4_int\", \"d5_int\", \"d6_int\", \"d7_int\", \"d8_int\"]].to_numpy()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def build_nonoverlapping_sequence(X, seq_num=4):\n",
    "    seq_len = X.shape[1] * seq_num\n",
    "    n = math.floor(X.shape[0] / seq_len)\n",
    "    r = X.shape[0] % seq_len\n",
    "    if r != 0:\n",
    "        # Cut off not divisible part\n",
    "        seqs = X[:-r].reshape(-1,32)\n",
    "    else:\n",
    "        seqs = X.reshape(-1,32)\n",
    "\n",
    "    return seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201536, 32)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xnew = build_nonoverlapping_sequence(X, 32)\n",
    "Xnew.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class UnsupervisedEmbedding(ABC):\n",
    "    def __init__(self, embedding_root: str = None, embedding_for: str = None,\n",
    "                 embedding_dim: int = 100, embedding_version: float = 1.0):\n",
    "        self.embedding_root = embedding_root\n",
    "        self.embedding_for = embedding_for\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embedding_version = embedding_version\n",
    "\n",
    "    @abstractmethod\n",
    "    def fit(self, X):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model_file_path(embedding_root: str = None, embedding_for: str = None,\n",
    "                             embedding_model='skipgram', embedding_wordNgrams: int = 1,\n",
    "                             embedding_dim: int = 100, train_seq_len: int = 10, embedding_version: float = 1.0,\n",
    "                             embedding_type='fasttext'):\n",
    "    filename = f\"{embedding_for}_{embedding_type}_{embedding_model}_\" \\\n",
    "               f\"{embedding_wordNgrams}wordNgram_{embedding_dim}dim_{train_seq_len}trainseq_v{embedding_version}.bin\"\n",
    "    print(os.path.join(embedding_root, filename))\n",
    "    return os.path.join(embedding_root, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FastTextEmbedding(UnsupervisedEmbedding):\n",
    "    def __init__(self, embedding_root: str = None, embedding_for: str = None,\n",
    "                 embedding_model='skipgram', embedding_wordNgrams: int = 1,\n",
    "                 embedding_dim: int = 100, embedding_version: float = 1.0,\n",
    "                 epochs: int = 10, minCount: int = 1, maxn: int = 0):\n",
    "        super().__init__(embedding_root, embedding_for, embedding_dim, embedding_version)\n",
    "        self.embedding_model = embedding_model\n",
    "\n",
    "        # Can use wordN grams by setting 2\n",
    "        # https://fasttext.cc/docs/en/supervised-tutorial.html\n",
    "        self.embedding_wordNgrams = embedding_wordNgrams\n",
    "\n",
    "        self.epochs = epochs\n",
    "        self.minCount = minCount\n",
    "        self.maxn = maxn\n",
    "\n",
    "        self.embedding_config = {\n",
    "            'embedding_root': self.embedding_root,\n",
    "            'embedding_for': self.embedding_for, 'embedding_model': self.embedding_model,\n",
    "            \"embedding_wordNgrams\": self.embedding_wordNgrams, 'embedding_dim': self.embedding_dim,\n",
    "            'embedding_version': self.embedding_version, 'embedding_type': 'fasttext'\n",
    "        }\n",
    "\n",
    "    def fit(self, X):\n",
    "        seq_len = X.shape[1]\n",
    "        # if X is not None:\n",
    "        #     seq_len = len(_tokenize_by_spaces(X[0])) \n",
    "        # print(f\"Calc BBBBBBBBBB {seq_len} , X.shape[1] = {X.shape[1]}\")\n",
    "\n",
    "\n",
    "        data_temp_file_path = FastTextEmbedding.generate_temp_seq_storage_file_path(self.embedding_for)\n",
    "        np.savetxt(data_temp_file_path, X.astype(int), fmt='%i')\n",
    "\n",
    "        # Create embeddings for event id https://fasttext.cc/docs/en/python-module.html\n",
    "        fasttext_model = fasttext.train_unsupervised(data_temp_file_path,\n",
    "                                                     model=self.embedding_model,\n",
    "                                                     dim=self.embedding_dim,\n",
    "                                                     wordNgrams=self.embedding_wordNgrams,\n",
    "                                                     epoch=self.epochs, minCount=self.minCount, maxn=self.maxn)\n",
    "        cfg_copy = self.embedding_config.copy()\n",
    "        cfg_copy[\"train_seq_len\"] = seq_len\n",
    "        model_file_path = generate_model_file_path(**cfg_copy)\n",
    "        fasttext_model.save_model(model_file_path)\n",
    "\n",
    "        os.remove(data_temp_file_path)\n",
    "\n",
    "        # print(fasttext_model.get_words())\n",
    "        # word_embeddings = model.get_output_matrix()\n",
    "        # print(word_embeddings)\n",
    "\n",
    "        return fasttext_model\n",
    "    \n",
    "    @staticmethod\n",
    "    def generate_temp_seq_storage_file_path(embedding_for=None):\n",
    "        return embedding_for + '_eventid_token_seq.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/jvana/carhacking/features\\Car_Hacking_Challenge_Dataset_rev20Mar2021_fasttext_skipgram_3wordNgram_100dim_32trainseq_v1.0.bin\n"
     ]
    }
   ],
   "source": [
    "fastText_embedding_cfg = {\n",
    "    'embedding_root': \"C:/Users/jvana/carhacking/features\",\n",
    "    'embedding_for': \"Car_Hacking_Challenge_Dataset_rev20Mar2021\", 'embedding_model': \"skipgram\",\n",
    "    \"embedding_wordNgrams\": 3, 'embedding_dim': 100,\n",
    "    'embedding_version': \"1.0\"\n",
    "}\n",
    "\n",
    "fasttext_embedding = FastTextEmbedding(**fastText_embedding_cfg)\n",
    "fasttext_model = fasttext_embedding.fit(Xnew) # fits and saves model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_text_from_model_file(embedding_root: str = None, embedding_for: str = None,\n",
    "                              embedding_model='skipgram', embedding_wordNgrams: int = 1,\n",
    "                              embedding_dim: int = 100, train_seq_len: int = 10, embedding_version: float = 1.0):\n",
    "    model_file_path = generate_model_file_path(embedding_root, embedding_for, embedding_model,\n",
    "                                               embedding_wordNgrams, embedding_dim, train_seq_len,\n",
    "                                               embedding_version, 'fasttext')\n",
    "    model = fasttext.load_model(model_file_path)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/jvana/carhacking/features\\Car_Hacking_Challenge_Dataset_rev20Mar2021_fasttext_skipgram_3wordNgram_100dim_32trainseq_v1.0.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "fastText_embedding_cfg = {\n",
    "    'embedding_root': \"C:/Users/jvana/carhacking/features\",\n",
    "    'embedding_for': \"Car_Hacking_Challenge_Dataset_rev20Mar2021\", 'embedding_model': \"skipgram\",\n",
    "    \"embedding_wordNgrams\": 3, 'embedding_dim': 100,\n",
    "    'embedding_version': \"1.0\", \"train_seq_len\": 32\n",
    "}\n",
    "\n",
    "fasttext_model = fast_text_from_model_file(**fastText_embedding_cfg)\n",
    "word_embeddings = np.array([fasttext_model.get_word_vector(str(word_token))\n",
    "                            for word_token in np.arange(0,255)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01350737, -0.03246043,  0.1353021 , ...,  0.03284965,\n",
       "         0.20701405, -0.00108776],\n",
       "       [-0.02180098, -0.07381336,  0.08867939, ..., -0.03638043,\n",
       "        -0.08245512, -0.01660034],\n",
       "       [ 0.02409102, -0.03610906,  0.00647557, ..., -0.05488613,\n",
       "        -0.06102106,  0.23384662],\n",
       "       ...,\n",
       "       [-0.12718815,  0.22688039,  0.08068047, ...,  0.11819232,\n",
       "         0.42247272, -0.3135497 ],\n",
       "       [-0.08785516, -0.02640463,  0.11216791, ..., -0.09137792,\n",
       "         0.1770951 ,  0.02200276],\n",
       "       [-0.07057732,  0.34931365,  0.27632374, ..., -0.1625063 ,\n",
       "         0.24944316, -0.03379932]], dtype=float32)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_word2vec_model_file_path(embedding_root: str = None, embedding_for: str = None,\n",
    "                             embedding_model='skipgram', embedding_wordNgrams: int = 1,\n",
    "                             embedding_dim: int = 100, train_seq_len: int = 10, embedding_version: float = 1.0,\n",
    "                             embedding_type='fasttext'):\n",
    "    filename = f\"{embedding_for}_{embedding_type}_{embedding_model}_\" \\\n",
    "               f\"{embedding_wordNgrams}wordNgram_{embedding_dim}dim_{train_seq_len}trainseq_v{embedding_version}.word2vec\"\n",
    "    return os.path.join(embedding_root, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_word2vec_model_bin_file_path(embedding_root: str = None, embedding_for: str = None,\n",
    "                             embedding_model='skipgram', embedding_wordNgrams: int = 1,\n",
    "                             embedding_dim: int = 100, train_seq_len: int = 10, embedding_version: float = 1.0,\n",
    "                             embedding_type='fasttext'):\n",
    "    filename = f\"{embedding_for}_{embedding_type}_{embedding_model}_\" \\\n",
    "               f\"{embedding_wordNgrams}wordNgram_{embedding_dim}dim_{train_seq_len}trainseq_v{embedding_version}.bin\"\n",
    "    return os.path.join(embedding_root, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "\n",
    "fastText_embedding_cfg = {\n",
    "    'embedding_root': \"C:/Users/jvana/carhacking/features\",\n",
    "    'embedding_for': \"Car_Hacking_Challenge_Dataset_rev20Mar2021\", 'embedding_model': \"skipgram\",\n",
    "    \"embedding_wordNgrams\": 3, 'embedding_dim': 100,\n",
    "    'embedding_version': \"1.0\", \"train_seq_len\": 32\n",
    "}\n",
    "\n",
    "model_bin_file_path = generate_word2vec_model_bin_file_path(**fastText_embedding_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/jvana/carhacking/features\\\\Car_Hacking_Challenge_Dataset_rev20Mar2021_fasttext_skipgram_3wordNgram_100dim_32trainseq_v1.0.bin'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bin_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xba in position 0: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jvana\\carhacking\\notebooks\\trial.ipynb Cell 24\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jvana/carhacking/notebooks/trial.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m wv \u001b[39m=\u001b[39m KeyedVectors\u001b[39m.\u001b[39;49mload_word2vec_format(model_bin_file_path, binary\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\jvana\\.conda\\envs\\carhacking\\lib\\site-packages\\gensim\\models\\keyedvectors.py:1629\u001b[0m, in \u001b[0;36mKeyedVectors.load_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header)\u001b[0m\n\u001b[0;32m   1582\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m   1583\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_word2vec_format\u001b[39m(\n\u001b[0;32m   1584\u001b[0m         \u001b[39mcls\u001b[39m, fname, fvocab\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, binary\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, encoding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mutf8\u001b[39m\u001b[39m'\u001b[39m, unicode_errors\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mstrict\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1585\u001b[0m         limit\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, datatype\u001b[39m=\u001b[39mREAL, no_header\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m   1586\u001b[0m     ):\n\u001b[0;32m   1587\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Load KeyedVectors from a file produced by the original C word2vec-tool format.\u001b[39;00m\n\u001b[0;32m   1588\u001b[0m \n\u001b[0;32m   1589\u001b[0m \u001b[39m    Warnings\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1627\u001b[0m \n\u001b[0;32m   1628\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1629\u001b[0m     \u001b[39mreturn\u001b[39;00m _load_word2vec_format(\n\u001b[0;32m   1630\u001b[0m         \u001b[39mcls\u001b[39;49m, fname, fvocab\u001b[39m=\u001b[39;49mfvocab, binary\u001b[39m=\u001b[39;49mbinary, encoding\u001b[39m=\u001b[39;49mencoding, unicode_errors\u001b[39m=\u001b[39;49municode_errors,\n\u001b[0;32m   1631\u001b[0m         limit\u001b[39m=\u001b[39;49mlimit, datatype\u001b[39m=\u001b[39;49mdatatype, no_header\u001b[39m=\u001b[39;49mno_header,\n\u001b[0;32m   1632\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\jvana\\.conda\\envs\\carhacking\\lib\\site-packages\\gensim\\models\\keyedvectors.py:1965\u001b[0m, in \u001b[0;36m_load_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header, binary_chunk_size)\u001b[0m\n\u001b[0;32m   1963\u001b[0m     fin \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mopen(fname, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m   1964\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1965\u001b[0m     header \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39;49mto_unicode(fin\u001b[39m.\u001b[39;49mreadline(), encoding\u001b[39m=\u001b[39;49mencoding)\n\u001b[0;32m   1966\u001b[0m     vocab_size, vector_size \u001b[39m=\u001b[39m [\u001b[39mint\u001b[39m(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m header\u001b[39m.\u001b[39msplit()]  \u001b[39m# throws for invalid file format\u001b[39;00m\n\u001b[0;32m   1967\u001b[0m \u001b[39mif\u001b[39;00m limit:\n",
      "File \u001b[1;32mc:\\Users\\jvana\\.conda\\envs\\carhacking\\lib\\site-packages\\gensim\\utils.py:364\u001b[0m, in \u001b[0;36many2unicode\u001b[1;34m(text, encoding, errors)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(text, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    363\u001b[0m     \u001b[39mreturn\u001b[39;00m text\n\u001b[1;32m--> 364\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mstr\u001b[39;49m(text, encoding, errors\u001b[39m=\u001b[39;49merrors)\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xba in position 0: invalid start byte"
     ]
    }
   ],
   "source": [
    "wv = KeyedVectors.load_word2vec_format(model_bin_file_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnpicklingError",
     "evalue": "invalid load key, '\\xba'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jvana\\carhacking\\notebooks\\trial.ipynb Cell 25\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jvana/carhacking/notebooks/trial.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgensim\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m Word2Vec\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jvana/carhacking/notebooks/trial.ipynb#X34sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Load the Word2Vec model\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jvana/carhacking/notebooks/trial.ipynb#X34sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m model \u001b[39m=\u001b[39m Word2Vec\u001b[39m.\u001b[39;49mload(model_bin_file_path)\n",
      "File \u001b[1;32mc:\\Users\\jvana\\.conda\\envs\\carhacking\\lib\\site-packages\\gensim\\models\\word2vec.py:1930\u001b[0m, in \u001b[0;36mload\u001b[1;34m(cls, rethrow, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1927\u001b[0m \u001b[39m# don't save properties that are merely calculated from others\u001b[39;00m\n\u001b[0;32m   1928\u001b[0m ignore \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(ignore)\u001b[39m.\u001b[39munion([\u001b[39m'\u001b[39m\u001b[39mcum_table\u001b[39m\u001b[39m'\u001b[39m, ])\n\u001b[0;32m   1929\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m(Word2Vec, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m_save_specials(\n\u001b[1;32m-> 1930\u001b[0m     fname, separately, sep_limit, ignore, pickle_protocol, compress, subname)\n",
      "File \u001b[1;32mc:\\Users\\jvana\\.conda\\envs\\carhacking\\lib\\site-packages\\gensim\\utils.py:485\u001b[0m, in \u001b[0;36mSaveLoad.load\u001b[1;34m(cls, fname, mmap)\u001b[0m\n\u001b[0;32m    481\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mloading \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m object from \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, fname)\n\u001b[0;32m    483\u001b[0m compress, subname \u001b[39m=\u001b[39m SaveLoad\u001b[39m.\u001b[39m_adapt_by_suffix(fname)\n\u001b[1;32m--> 485\u001b[0m obj \u001b[39m=\u001b[39m unpickle(fname)\n\u001b[0;32m    486\u001b[0m obj\u001b[39m.\u001b[39m_load_specials(fname, mmap, compress, subname)\n\u001b[0;32m    487\u001b[0m obj\u001b[39m.\u001b[39madd_lifecycle_event(\u001b[39m\"\u001b[39m\u001b[39mloaded\u001b[39m\u001b[39m\"\u001b[39m, fname\u001b[39m=\u001b[39mfname)\n",
      "File \u001b[1;32mc:\\Users\\jvana\\.conda\\envs\\carhacking\\lib\\site-packages\\gensim\\utils.py:1460\u001b[0m, in \u001b[0;36munpickle\u001b[1;34m(fname)\u001b[0m\n\u001b[0;32m   1446\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Load object from `fname`, using smart_open so that `fname` can be on S3, HDFS, compressed etc.\u001b[39;00m\n\u001b[0;32m   1447\u001b[0m \n\u001b[0;32m   1448\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1457\u001b[0m \n\u001b[0;32m   1458\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1459\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(fname, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m-> 1460\u001b[0m     \u001b[39mreturn\u001b[39;00m _pickle\u001b[39m.\u001b[39;49mload(f, encoding\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mlatin1\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "\u001b[1;31mUnpicklingError\u001b[0m: invalid load key, '\\xba'."
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Load the Word2Vec model\n",
    "model = Word2Vec.load(model_bin_file_path)\n",
    "\n",
    "# Use the model for various NLP tasks\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carhacking",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
